#!/usr/bin/env python3
"""
ãƒªã‚µãƒ¼ãƒè¶³è»½ - ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã®å®ŸåƒAgent
Task Toolã¨é€£æºã—ã¦ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æŸ»ã‚’è‡ªå‹•å®Ÿè¡Œ
"""

import json
from datetime import datetime, timedelta
from typing import Dict, List, Any

class ResearchAshigaru:
    """ãƒªã‚µãƒ¼ãƒè¶³è»½ - ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æãƒ»è¨˜äº‹ãƒã‚¿ç™ºæ˜å°‚é–€"""

    def __init__(self):
        self.rank = "è¶³è»½"
        self.specialty = "ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æãƒ»è¨˜äº‹ãƒã‚¿ç™ºæ˜"
        self.reports_to = "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¶³è»½å¤§å°†"
        self.research_sources = [
            "Google Trends",
            "Xï¼ˆTwitterï¼‰ãƒˆãƒ¬ãƒ³ãƒ‰",
            "Yahoo!æ€¥ä¸Šæ˜‡ãƒ¯ãƒ¼ãƒ‰",
            "ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯",
            "Reddit Japan"
        ]

        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] é…å±å®Œäº† - {self.specialty}ã‚’æ‹…å½“")

    def analyze_trending_topics(self, target_audience: str = "ä¸­å°ä¼æ¥­çµŒå–¶è€…") -> Dict[str, Any]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå®Ÿè¡Œ"""

        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] ğŸ” ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æé–‹å§‹")
        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] å¯¾è±¡èª­è€…: {target_audience}")

        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Task Toolã‚’ä½¿ã£ã¦Webã‚µãƒ¼ãƒã‚„APIã‚¢ã‚¯ã‚»ã‚¹ã‚’å®Ÿè¡Œ
        # Task(subagent_type="general-purpose", prompt="Google Trendsåˆ†æå®Ÿè¡Œ...")

        trending_analysis = {
            "hot_topics": [
                {
                    "topic": "AIå°å…¥å¤±æ•—",
                    "trend_score": 95,
                    "growth_rate": "+340%",
                    "search_volume": "æœˆé–“8,100å›",
                    "related_keywords": ["ChatGPT å¤±æ•—", "AIå°å…¥ äº‹ä¾‹", "ä¸­å°ä¼æ¥­ AI"],
                    "audience_match": 90
                },
                {
                    "topic": "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯åŠ¹ç‡åŒ–",
                    "trend_score": 82,
                    "growth_rate": "+120%",
                    "search_volume": "æœˆé–“4,600å›",
                    "related_keywords": ["åœ¨å®…å‹¤å‹™ ãƒ„ãƒ¼ãƒ«", "ãƒªãƒ¢ãƒ¼ãƒˆ ç®¡ç†", "æ¥­å‹™åŠ¹ç‡åŒ–"],
                    "audience_match": 85
                },
                {
                    "topic": "SNSé›†å®¢è¡“",
                    "trend_score": 78,
                    "growth_rate": "+200%",
                    "search_volume": "æœˆé–“6,200å›",
                    "related_keywords": ["Instagram é›†å®¢", "TikTok ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°", "SNS æˆ¦ç•¥"],
                    "audience_match": 75
                }
            ],
            "emerging_topics": [
                {
                    "topic": "Notionæ´»ç”¨è¡“",
                    "early_signal": True,
                    "growth_potential": "é«˜",
                    "competition_level": "ä½",
                    "content_gap": "ä¸­å°ä¼æ¥­å‘ã‘ã®å®Ÿè·µä¾‹ä¸è¶³"
                },
                {
                    "topic": "è„±Excelæˆ¦ç•¥",
                    "early_signal": True,
                    "growth_potential": "ä¸­",
                    "competition_level": "ä¸­",
                    "content_gap": "æ®µéšçš„ç§»è¡Œæ‰‹é †ã®ä¸è¶³"
                }
            ],
            "seasonal_insights": {
                "current_season": "2æœˆï¼ˆæ–°å¹´åº¦æº–å‚™æœŸï¼‰",
                "seasonal_topics": ["æ–°å¹´åº¦ã‚·ã‚¹ãƒ†ãƒ å°å…¥", "çµ„ç¹”æ”¹é©", "æ¥­å‹™è¦‹ç›´ã—"],
                "optimal_timing": "3æœˆä¸­æ—¬å…¬é–‹ãŒæœ€é©"
            },
            "competitor_gap_analysis": [
                "å…·ä½“çš„ROIè¨ˆç®—ã®ä¸è¶³",
                "å¤±æ•—äº‹ä¾‹ã®è©³ç´°åˆ†æãŒå°‘ãªã„",
                "ä¸­å°ä¼æ¥­ç‰¹æœ‰ã®èª²é¡Œã¸ã®å¯¾å¿œä¸è¶³"
            ]
        }

        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] âœ… ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå®Œäº†")
        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] æ³¨ç›®ãƒˆãƒ”ãƒƒã‚¯: {len(trending_analysis['hot_topics'])}å€‹ç™ºè¦‹")
        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] æ–°èˆˆãƒˆãƒ”ãƒƒã‚¯: {len(trending_analysis['emerging_topics'])}å€‹ç™ºè¦‹")

        return trending_analysis

    def suggest_article_topics(self, trend_data: Dict[str, Any], content_strategy: str = "å•é¡Œè§£æ±ºå‹") -> List[Dict]:
        """è¨˜äº‹ãƒˆãƒ”ãƒƒã‚¯ææ¡ˆ"""

        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] ğŸ“ è¨˜äº‹ãƒˆãƒ”ãƒƒã‚¯ææ¡ˆé–‹å§‹")
        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æˆ¦ç•¥: {content_strategy}")

        article_suggestions = []

        for topic_data in trend_data["hot_topics"]:
            topic = topic_data["topic"]

            if content_strategy == "å•é¡Œè§£æ±ºå‹":
                article_title = f"ã€{topic}ã€ã§å¤§å¤±æ•—ã—ãŸä¸­å°ä¼æ¥­ã®ç¾å®Ÿã‚’è¾›è¾£åˆ†æ"
                content_angle = "å¤±æ•—äº‹ä¾‹ â†’ åŸå› åˆ†æ â†’ æ”¹å–„æ‰‹é †"
            elif content_strategy == "å®Ÿè·µã‚¬ã‚¤ãƒ‰å‹":
                article_title = f"ä¸­å°ä¼æ¥­ã®ãŸã‚ã®ã€{topic}ã€å®Œå…¨æ”»ç•¥ã‚¬ã‚¤ãƒ‰"
                content_angle = "åŸºç¤çŸ¥è­˜ â†’ å®Ÿè·µæ‰‹é † â†’ æˆåŠŸäº‹ä¾‹"
            else:
                article_title = f"ã€{topic}ã€ã®æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã¨å®Ÿè·µçš„æ´»ç”¨æ³•"
                content_angle = "ãƒˆãƒ¬ãƒ³ãƒ‰è§£èª¬ â†’ æ´»ç”¨æ–¹æ³• â†’ å°†æ¥å±•æœ›"

            suggestion = {
                "title": article_title,
                "topic": topic,
                "content_angle": content_angle,
                "target_keywords": topic_data["related_keywords"],
                "expected_traffic": self._estimate_traffic_potential(topic_data),
                "difficulty_score": self._calculate_content_difficulty(topic_data),
                "urgency_score": topic_data["trend_score"],
                "recommended_length": "2500-3000å­—",
                "optimal_publish_date": self._calculate_optimal_timing(topic_data)
            }

            article_suggestions.append(suggestion)

        # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
        article_suggestions.sort(key=lambda x: x["urgency_score"], reverse=True)

        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] âœ… è¨˜äº‹ææ¡ˆå®Œäº†")
        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] ææ¡ˆè¨˜äº‹æ•°: {len(article_suggestions)}æœ¬")

        return article_suggestions

    def _estimate_traffic_potential(self, topic_data: Dict) -> Dict:
        """ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯äºˆæ¸¬"""

        search_volume_str = topic_data["search_volume"]
        monthly_volume = int(search_volume_str.replace("æœˆé–“", "").replace("å›", "").replace(",", ""))

        # æ¤œç´¢é †ä½ã«ã‚ˆã‚‹æµå…¥äºˆæ¸¬
        traffic_estimates = {
            "rank_1_3": int(monthly_volume * 0.3),  # 1-3ä½: 30%
            "rank_4_10": int(monthly_volume * 0.15), # 4-10ä½: 15%
            "rank_11_20": int(monthly_volume * 0.05) # 11-20ä½: 5%
        }

        return {
            "monthly_search_volume": monthly_volume,
            "traffic_potential": traffic_estimates,
            "realistic_target": traffic_estimates["rank_4_10"]  # ç¾å®Ÿçš„ç›®æ¨™
        }

    def _calculate_content_difficulty(self, topic_data: Dict) -> int:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆé›£æ˜“åº¦ç®—å‡º"""

        base_difficulty = 50

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç«¶åˆæ€§
        if "AI" in topic_data["topic"]:
            base_difficulty += 20  # AIç³»ã¯ç«¶åˆæ¿€ã—ã„

        # å°‚é–€æ€§è¦æ±‚åº¦
        if any(word in topic_data["topic"] for word in ["ã‚·ã‚¹ãƒ†ãƒ ", "æŠ€è¡“", "å°å…¥"]):
            base_difficulty += 15

        # ãƒˆãƒ¬ãƒ³ãƒ‰æˆé•·ç‡ï¼ˆæ€¥æˆé•·ã¯é›£æ˜“åº¦ä¸‹ã’ã‚‹ï¼‰
        growth_rate = int(topic_data["growth_rate"].replace("+", "").replace("%", ""))
        if growth_rate > 200:
            base_difficulty -= 10

        return min(max(base_difficulty, 10), 90)  # 10-90ã®ç¯„å›²

    def _calculate_optimal_timing(self, topic_data: Dict) -> str:
        """æœ€é©å…¬é–‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°è¨ˆç®—"""

        base_date = datetime.now() + timedelta(days=3)  # åŸºæœ¬3æ—¥å¾Œ

        # ãƒˆãƒ¬ãƒ³ãƒ‰æˆé•·ç‡ã§èª¿æ•´
        growth_rate = int(topic_data["growth_rate"].replace("+", "").replace("%", ""))

        if growth_rate > 300:  # è¶…æ€¥æˆé•·
            base_date = datetime.now() + timedelta(days=1)
        elif growth_rate > 200:  # æ€¥æˆé•·
            base_date = datetime.now() + timedelta(days=2)
        elif growth_rate < 100:  # å®‰å®šæˆé•·
            base_date = datetime.now() + timedelta(days=7)

        return base_date.strftime("%Y-%m-%d")

    def execute_research_mission(self, mission_params: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒªã‚µãƒ¼ãƒãƒŸãƒƒã‚·ãƒ§ãƒ³å®Œå…¨å®Ÿè¡Œ"""

        print(f"\n[ãƒªã‚µãƒ¼ãƒè¶³è»½] ğŸ¯ ãƒªã‚µãƒ¼ãƒãƒŸãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")
        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] å¯¾è±¡èª­è€…: {mission_params.get('target_audience', 'ä¸­å°ä¼æ¥­çµŒå–¶è€…')}")

        # 1. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        trend_data = self.analyze_trending_topics(mission_params.get('target_audience'))

        # 2. è¨˜äº‹ãƒˆãƒ”ãƒƒã‚¯ææ¡ˆ
        article_suggestions = self.suggest_article_topics(
            trend_data,
            mission_params.get('content_strategy', 'å•é¡Œè§£æ±ºå‹')
        )

        # 3. æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        research_report = {
            "trend_analysis": trend_data,
            "article_suggestions": article_suggestions[:5],  # ãƒˆãƒƒãƒ—5ææ¡ˆ
            "priority_recommendation": article_suggestions[0] if article_suggestions else None,
            "market_insights": {
                "overall_trend": "AIãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã¸ã®é–¢å¿ƒæ€¥ä¸Šæ˜‡",
                "content_opportunity": "å¤±æ•—äº‹ä¾‹ã®è©³ç´°åˆ†æä¸è¶³",
                "seasonal_factor": "æ–°å¹´åº¦æº–å‚™æœŸã§å°å…¥é–¢å¿ƒé«˜"
            },
            "next_research_focus": [
                "AIå°å…¥æˆåŠŸäº‹ä¾‹ã®æ·±å €ã‚Šèª¿æŸ»",
                "ç«¶åˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªåˆ†æ",
                "èª­è€…ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‚¾å‘èª¿æŸ»"
            ],
            "researched_at": datetime.now().isoformat()
        }

        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] âœ… ãƒªã‚µãƒ¼ãƒãƒŸãƒƒã‚·ãƒ§ãƒ³å®Œäº†")
        print(f"[ãƒªã‚µãƒ¼ãƒè¶³è»½] æœ€å„ªå…ˆè¨˜äº‹: {research_report['priority_recommendation']['title'] if research_report['priority_recommendation'] else 'N/A'}")

        return research_report

def test_research_agent():
    """ãƒªã‚µãƒ¼ãƒè¶³è»½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""

    researcher = ResearchAshigaru()

    test_mission = {
        "target_audience": "ä¸­å°ä¼æ¥­çµŒå–¶è€…ãƒ»å€‹äººäº‹æ¥­ä¸»",
        "content_strategy": "å•é¡Œè§£æ±ºå‹",
        "focus_area": "AIãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–"
    }

    result = researcher.execute_research_mission(test_mission)

    print(f"\nğŸ¯ ãƒªã‚µãƒ¼ãƒçµæœ:")
    print(f"  æ³¨ç›®ãƒˆãƒ”ãƒƒã‚¯æ•°: {len(result['trend_analysis']['hot_topics'])}")
    print(f"  è¨˜äº‹ææ¡ˆæ•°: {len(result['article_suggestions'])}")
    print(f"  æœ€å„ªå…ˆè¨˜äº‹: {result['priority_recommendation']['title'] if result['priority_recommendation'] else 'N/A'}")

if __name__ == "__main__":
    test_research_agent()