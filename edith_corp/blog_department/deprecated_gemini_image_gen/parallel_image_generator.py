#!/usr/bin/env python3
"""
ä¸¦åˆ—ç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  - Gemini 3 Pro Image Preview
4ã¤ã®APIã‚­ãƒ¼ã§ä¸¦åˆ—å‡¦ç†ã€40å€é«˜é€ŸåŒ–å®Ÿç¾
"""

import os
import json
import base64
import requests
from datetime import datetime
from typing import Dict, List, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from pathlib import Path
from dotenv import load_dotenv

class ParallelImageGenerator:
    """4ä¸¦åˆ—ã§é«˜é€Ÿç”»åƒç”Ÿæˆã‚’å®Ÿç¾"""

    def __init__(self):
        # .env.localã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ï¼‰
        from pathlib import Path as PathLib
        project_root = PathLib(__file__).parent.parent.parent.parent  # deprecated â†’ blog_dept â†’ edith_corp â†’ 000AGENTS
        env_path = project_root / '.env.local'
        if env_path.exists():
            load_dotenv(str(env_path))

        # 4ã¤ã®APIã‚­ãƒ¼ã‚’å–å¾—
        self.api_keys = []
        for i in range(1, 5):
            key = os.getenv(f'GEMINI_IMAGE_API_KEY_{i}')
            if key:
                self.api_keys.append(key)

        if not self.api_keys:
            raise ValueError("No GEMINI_IMAGE_API_KEY found in environment")

        print(f"âœ… {len(self.api_keys)}å€‹ã®APIã‚­ãƒ¼ã§ä¸¦åˆ—å‡¦ç†ã‚’å®Ÿè¡Œ")

        # Gemini 1.5 Flash ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        self.image_endpoint = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"

    def extract_keywords_from_content(self, content: str, max_keywords: int = 3) -> List[str]:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã—ï¼‰"""

        # ãƒ“ã‚¸ãƒã‚¹ç”¨èªã®è‹±èªå¤‰æ›è¾æ›¸
        term_mapping = {
            'AI': 'ai',
            'äººå·¥çŸ¥èƒ½': 'ai',
            'ChatGPT': 'chatgpt',
            'Excel': 'excel',
            'VBA': 'vba',
            'ãƒ”ãƒœãƒƒãƒˆ': 'pivot',
            'ä¸­å°ä¼æ¥­': 'sme',
            'FAX': 'fax',
            'ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–': 'digitization',
            'DX': 'dx',
            'å¤±æ•—': 'failure',
            'åˆ†æ': 'analysis',
            'ROI': 'roi',
            'åŠ¹æœ': 'effect',
            'ãƒ„ãƒ¼ãƒ«': 'tools',
            'è‡ªå‹•åŒ–': 'automation',
            'åŠ¹ç‡åŒ–': 'efficiency',
            'æ”¹å–„': 'improvement',
            'æˆ¦ç•¥': 'strategy',
            'ãƒã‚¯ãƒ­': 'macro',
            'ã‚¯ã‚¨ãƒª': 'query',
            'ãƒ‡ãƒ¼ã‚¿': 'data',
            'ä½œæ¥­': 'work',
            'æ™‚é–“': 'time',
            'å‰Šæ¸›': 'reduction',
            'ã‚¨ãƒ©ãƒ¼': 'error',
            'å“è³ª': 'quality',
            'è·äºº': 'craftsman',
            'ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ': 'architect'
        }

        keywords = []
        content_lower = content.lower()

        # å„ªå…ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        for term, english in term_mapping.items():
            if term.lower() in content_lower:
                if english not in keywords:
                    keywords.append(english)
                    if len(keywords) >= max_keywords:
                        return keywords

        # è¶³ã‚Šãªã„å ´åˆã¯æ±ç”¨çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
        generic_terms = ['business', 'tech', 'innovation']
        for term in generic_terms:
            if len(keywords) < max_keywords:
                keywords.append(term)

        return keywords[:max_keywords]

    def generate_image_filename(self, section_data: Dict) -> str:
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã—ï¼‰"""

        content = f"{section_data.get('title', '')} {section_data.get('content', '')}"
        keywords = self.extract_keywords_from_content(content)

        # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã—ã§ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        filename = '_'.join(keywords) + '.png'

        return filename

    def generate_single_image(self, api_key: str, section_data: Dict, output_path: str, index: int) -> Dict:
        """å˜ä¸€ç”»åƒã‚’ç”Ÿæˆï¼ˆå„ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰"""

        start_time = time.time()

        headers = {
            'Content-Type': 'application/json',
        }

        # é«˜å“è³ªç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        style_prompt = """
        Professional business infographic style.
        Modern, clean design with professional color scheme.
        High contrast, clear visual hierarchy.
        Minimalist but impactful.
        Corporate presentation quality.
        Size: 1920x1080 pixels.
        """

        payload = {
            "contents": [{
                "parts": [{
                    "text": f"Generate a high-quality business image.\n{style_prompt}\n\nTopic: {section_data['content']}\n\nIMPORTANT: Output the image in base64 encoded format."
                }]
            }],
            "generationConfig": {
                "temperature": 0.4,
                "topP": 1,
                "topK": 32,
                "maxOutputTokens": 8192
            }
        }

        try:
            print(f"  ğŸ¨ Worker-{index % len(self.api_keys) + 1}: {section_data['title']}...")

            response = requests.post(
                f"{self.image_endpoint}?key={api_key}",
                headers=headers,
                json=payload,
                timeout=600
            )

            if response.status_code == 200:
                result = response.json()

                # ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                if 'candidates' in result and result['candidates']:
                    candidate = result['candidates'][0]
                    if 'content' in candidate and 'parts' in candidate['content']:
                        for part in candidate['content']['parts']:
                            # ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰base64ç”»åƒã‚’æŠ½å‡º
                            if 'text' in part:
                                text_content = part['text']
                                # base64ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
                                if 'data:image' in text_content or 'iVBOR' in text_content:
                                    # base64ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                                    import re
                                    base64_pattern = r'(?:data:image/\w+;base64,)?([A-Za-z0-9+/]+=*)'
                                    matches = re.findall(base64_pattern, text_content)
                                    if matches:
                                        # æœ€ã‚‚é•·ã„ãƒãƒƒãƒã‚’ç”»åƒãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹
                                        image_data = max(matches, key=len)
                                        try:
                                            image_bytes = base64.b64decode(image_data)
                                            with open(output_path, 'wb') as f:
                                                f.write(image_bytes)

                                            elapsed = time.time() - start_time
                                            print(f"    âœ… Worker-{index % len(self.api_keys) + 1}: å®Œäº† ({elapsed:.1f}ç§’)")

                                            return {
                                                'success': True,
                                                'path': output_path,
                                                'time': elapsed
                                            }
                                        except:
                                            pass

                            # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ç”»åƒãŒè¿”ã•ã‚Œã‚‹å ´åˆ
                            elif 'inlineData' in part:
                                image_data = part['inlineData']
                                if 'data' in image_data:
                                    image_bytes = base64.b64decode(image_data['data'])
                                    with open(output_path, 'wb') as f:
                                        f.write(image_bytes)

                                    elapsed = time.time() - start_time
                                    print(f"    âœ… Worker-{index % len(self.api_keys) + 1}: å®Œäº† ({elapsed:.1f}ç§’)")

                                    return {
                                        'success': True,
                                        'path': output_path,
                                        'time': elapsed
                                    }

            print(f"    âŒ Worker-{index % len(self.api_keys) + 1}: å¤±æ•— - Status: {response.status_code}")
            return {'success': False, 'error': f"Status: {response.status_code}"}

        except Exception as e:
            print(f"    âŒ Worker-{index % len(self.api_keys) + 1}: ã‚¨ãƒ©ãƒ¼ - {str(e)}")
            return {'success': False, 'error': str(e)}

    def distribute_tasks(self, num_images: int) -> List[int]:
        """ã‚¿ã‚¹ã‚¯ã‚’APIã‚­ãƒ¼é–“ã§åˆ†é…"""

        num_workers = len(self.api_keys)
        base_load = num_images // num_workers
        remainder = num_images % num_workers

        distribution = [base_load] * num_workers
        for i in range(remainder):
            distribution[i] += 1

        # 0ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã¯é™¤å¤–
        distribution = [d for d in distribution if d > 0]

        return distribution

    def generate_article_images_parallel(self, article_data: Dict) -> Dict:
        """è¨˜äº‹ã®å…¨ç”»åƒã‚’ä¸¦åˆ—ç”Ÿæˆ"""

        start_time = time.time()

        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’çµ±ä¸€ä»•æ§˜ã«åˆã‚ã›ã‚‹
        date_str = datetime.now().strftime('%Y%m%d')
        slug = article_data.get('slug', 'untitled')

        # è¨˜äº‹ã¨ç”»åƒã®çµ±ä¸€ä¿å­˜å…ˆï¼ˆç›¸å¯¾ãƒ‘ã‚¹ï¼‰
        from pathlib import Path as PathLib
        blog_dept_dir = PathLib(__file__).parent.parent  # deprecated â†’ blog_department
        article_dir = blog_dept_dir / 'articles' / f"{date_str}_{slug}"
        images_dir = article_dir / 'images'

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        Path(images_dir).mkdir(parents=True, exist_ok=True)

        print(f"\nğŸ“ ä¿å­˜å…ˆ: {images_dir}")

        # ç”»åƒç”Ÿæˆã‚¿ã‚¹ã‚¯ã®æº–å‚™
        tasks = []

        # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒ
        if article_data.get('theme'):
            tasks.append({
                'title': 'ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒ',
                'content': f"{article_data['title']} - {article_data['theme']}"
            })

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”»åƒ
        for section in article_data.get('sections', []):
            tasks.append(section)

        num_images = len(tasks)
        distribution = self.distribute_tasks(num_images)

        print(f"\nğŸš€ {num_images}æšã®ç”»åƒã‚’{len(distribution)}ä¸¦åˆ—ã§ç”Ÿæˆé–‹å§‹")
        print(f"   è² è·åˆ†æ•£: {distribution}")

        results = []

        # ä¸¦åˆ—å®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=len(self.api_keys)) as executor:
            futures = []
            task_index = 0

            for worker_id, num_tasks in enumerate(distribution):
                api_key = self.api_keys[worker_id]

                for _ in range(num_tasks):
                    if task_index < len(tasks):
                        task = tasks[task_index]
                        filename = self.generate_image_filename(task)
                        output_path = os.path.join(images_dir, filename)

                        future = executor.submit(
                            self.generate_single_image,
                            api_key,
                            task,
                            output_path,
                            task_index
                        )
                        futures.append((future, task['title']))
                        task_index += 1

            # çµæœåé›†
            for future, title in futures:
                result = future.result()
                result['title'] = title
                results.append(result)

        # çµ±è¨ˆæƒ…å ±
        elapsed_total = time.time() - start_time
        successful = sum(1 for r in results if r['success'])

        print(f"\nâ±ï¸  ç·å‡¦ç†æ™‚é–“: {elapsed_total:.1f}ç§’")
        print(f"ğŸ“Š æˆåŠŸç‡: {successful}/{num_images}æš")

        if successful == num_images:
            print("ğŸ‰ å…¨ç”»åƒã®ç”Ÿæˆã«æˆåŠŸï¼")

        return {
            'article_directory': article_dir,
            'images_directory': images_dir,
            'total_images': num_images,
            'successful_images': successful,
            'total_time': elapsed_total,
            'results': results
        }