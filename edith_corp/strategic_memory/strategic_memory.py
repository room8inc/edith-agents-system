#!/usr/bin/env python3
"""
æˆ¦ç•¥çš„è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ  - è‡ªå¾‹çš„ãªå­¦ç¿’ãƒ»è¨˜éŒ²ãƒ»æ”¹å–„
é‡è¦ãªç™ºè¦‹ã‚„æˆ¦ç•¥ã‚’è‡ªå‹•çš„ã«ä¿å­˜ãƒ»æ´»ç”¨
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

class StrategicMemory:
    """æˆ¦ç•¥çš„è¨˜æ†¶ã®è‡ªå¾‹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.memory_root = Path("/Users/tsuruta/Documents/000AGENTS/edith_corp/strategic_memory")
        self.memory_root.mkdir(exist_ok=True)

        # è¨˜æ†¶ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.dirs = {
            "strategies": self.memory_root / "strategies",
            "discoveries": self.memory_root / "discoveries",
            "performance": self.memory_root / "performance",
            "patterns": self.memory_root / "patterns",
            "failures": self.memory_root / "failures"
        }

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        for dir_path in self.dirs.values():
            dir_path.mkdir(exist_ok=True)

        # ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯åˆæœŸåŒ–
        self.memory_bank = self._load_memory_bank()

        print(f"[æˆ¦ç•¥è¨˜æ†¶] è‡ªå¾‹è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
        print(f"[æˆ¦ç•¥è¨˜æ†¶] è¨˜æ†¶ã‚«ãƒ†ã‚´ãƒª: {len(self.dirs)}ç¨®é¡")

    def _load_memory_bank(self) -> Dict[str, Any]:
        """æ—¢å­˜ã®è¨˜æ†¶ãƒãƒ³ã‚¯ã‚’èª­ã¿è¾¼ã¿"""

        bank_file = self.memory_root / "memory_bank.json"

        if bank_file.exists():
            with open(bank_file, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            return {
                "total_memories": 0,
                "categories": {
                    "strategies": [],
                    "discoveries": [],
                    "performance": [],
                    "patterns": [],
                    "failures": []
                },
                "last_updated": None
            }

    def auto_save_insight(self, insight_type: str, data: Dict[str, Any], context: str = None) -> bool:
        """é‡è¦ãªç™ºè¦‹ã‚’è‡ªå‹•ä¿å­˜"""

        print(f"[æˆ¦ç•¥è¨˜æ†¶] ğŸ’¾ è‡ªå‹•ä¿å­˜é–‹å§‹: {insight_type}")

        # ã‚¤ãƒ³ã‚µã‚¤ãƒˆã®åˆ†é¡ã¨å‡¦ç†
        if insight_type == "success_pattern":
            return self._save_success_pattern(data, context)

        elif insight_type == "keyword_discovery":
            return self._save_keyword_discovery(data, context)

        elif insight_type == "performance_milestone":
            return self._save_performance_milestone(data, context)

        elif insight_type == "failure_learning":
            return self._save_failure_learning(data, context)

        elif insight_type == "strategic_decision":
            return self._save_strategic_decision(data, context)

        else:
            # æœªåˆ†é¡ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚‚ä¿å­˜
            return self._save_general_insight(insight_type, data, context)

    def _save_success_pattern(self, data: Dict[str, Any], context: str) -> bool:
        """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¿å­˜"""

        pattern = {
            "pattern_id": f"success_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "pattern_type": data.get("type", "unknown"),
            "description": data.get("description", ""),
            "metrics": data.get("metrics", {}),
            "reproducibility": data.get("reproducibility", "unknown"),
            "context": context,
            "applied_count": 0,
            "success_rate": 0.0
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        pattern_file = self.dirs["patterns"] / f"{pattern['pattern_id']}.json"
        with open(pattern_file, "w", encoding="utf-8") as f:
            json.dump(pattern, f, ensure_ascii=False, indent=2)

        # ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã«è¿½åŠ 
        self.memory_bank["categories"]["patterns"].append({
            "id": pattern["pattern_id"],
            "type": pattern["pattern_type"],
            "metrics": pattern["metrics"],
            "file": str(pattern_file)
        })

        # æˆ¦ç•¥ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªå‹•æ›´æ–°
        self._update_strategy_document(pattern)

        print(f"[æˆ¦ç•¥è¨˜æ†¶] âœ… æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ä¿å­˜: {pattern['pattern_id']}")
        return True

    def _save_keyword_discovery(self, data: Dict[str, Any], context: str) -> bool:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç™ºè¦‹ã®ä¿å­˜"""

        discovery = {
            "discovery_id": f"keyword_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "keyword": data.get("keyword", ""),
            "search_volume": data.get("search_volume", 0),
            "competition": data.get("competition", "unknown"),
            "ctr": data.get("ctr", 0),
            "position": data.get("position", 0),
            "potential_traffic": data.get("potential_traffic", 0),
            "context": context,
            "status": "discovered",
            "action_taken": None
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        discovery_file = self.dirs["discoveries"] / f"{discovery['discovery_id']}.json"
        with open(discovery_file, "w", encoding="utf-8") as f:
            json.dump(discovery, f, ensure_ascii=False, indent=2)

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒ³ã‚¯ã«è¿½åŠ 
        self._append_to_keyword_bank(discovery)

        print(f"[æˆ¦ç•¥è¨˜æ†¶] âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç™ºè¦‹ä¿å­˜: {discovery['keyword']}")
        return True

    def _save_performance_milestone(self, data: Dict[str, Any], context: str) -> bool:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®ä¿å­˜"""

        milestone = {
            "milestone_id": f"perf_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "metric_name": data.get("metric", ""),
            "value": data.get("value", 0),
            "previous_value": data.get("previous_value", 0),
            "change_percentage": data.get("change_percentage", 0),
            "target_value": data.get("target_value", 0),
            "achievement_rate": data.get("achievement_rate", 0),
            "context": context
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        perf_file = self.dirs["performance"] / f"{milestone['milestone_id']}.json"
        with open(perf_file, "w", encoding="utf-8") as f:
            json.dump(milestone, f, ensure_ascii=False, indent=2)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰æ›´æ–°
        self._update_performance_trends(milestone)

        print(f"[æˆ¦ç•¥è¨˜æ†¶] âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²: {milestone['metric_name']} = {milestone['value']}")
        return True

    def _save_failure_learning(self, data: Dict[str, Any], context: str) -> bool:
        """å¤±æ•—ã‹ã‚‰ã®å­¦ç¿’ã‚’ä¿å­˜"""

        learning = {
            "learning_id": f"failure_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "failure_type": data.get("type", "unknown"),
            "description": data.get("description", ""),
            "root_cause": data.get("root_cause", "unknown"),
            "impact": data.get("impact", {}),
            "lesson_learned": data.get("lesson", ""),
            "prevention_measure": data.get("prevention", ""),
            "context": context,
            "prevented_count": 0
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        failure_file = self.dirs["failures"] / f"{learning['learning_id']}.json"
        with open(failure_file, "w", encoding="utf-8") as f:
            json.dump(learning, f, ensure_ascii=False, indent=2)

        print(f"[æˆ¦ç•¥è¨˜æ†¶] âœ… å¤±æ•—å­¦ç¿’ä¿å­˜: {learning['failure_type']}")
        return True

    def _save_strategic_decision(self, data: Dict[str, Any], context: str) -> bool:
        """æˆ¦ç•¥çš„æ±ºå®šã®ä¿å­˜"""

        decision = {
            "decision_id": f"strategy_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "decision_type": data.get("type", "unknown"),
            "title": data.get("title", ""),
            "rationale": data.get("rationale", ""),
            "expected_outcome": data.get("expected_outcome", {}),
            "actual_outcome": None,
            "status": "active",
            "context": context
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        strategy_file = self.dirs["strategies"] / f"{decision['decision_id']}.json"
        with open(strategy_file, "w", encoding="utf-8") as f:
            json.dump(decision, f, ensure_ascii=False, indent=2)

        print(f"[æˆ¦ç•¥è¨˜æ†¶] âœ… æˆ¦ç•¥æ±ºå®šä¿å­˜: {decision['title']}")
        return True

    def _save_general_insight(self, insight_type: str, data: Dict[str, Any], context: str) -> bool:
        """æ±ç”¨ã‚¤ãƒ³ã‚µã‚¤ãƒˆã®ä¿å­˜"""

        insight = {
            "insight_id": f"general_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "type": insight_type,
            "data": data,
            "context": context
        }

        # é©åˆ‡ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
        general_file = self.memory_root / f"general_{insight['insight_id']}.json"
        with open(general_file, "w", encoding="utf-8") as f:
            json.dump(insight, f, ensure_ascii=False, indent=2)

        print(f"[æˆ¦ç•¥è¨˜æ†¶] âœ… ã‚¤ãƒ³ã‚µã‚¤ãƒˆä¿å­˜: {insight_type}")
        return True

    def _update_strategy_document(self, pattern: Dict[str, Any]):
        """æˆ¦ç•¥ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è‡ªå‹•æ›´æ–°"""

        strategy_doc = self.memory_root.parent / "blog_department" / "seo_strategy.md"

        if not strategy_doc.exists():
            return

        # æ—¢å­˜å†…å®¹èª­ã¿è¾¼ã¿
        with open(strategy_doc, "r", encoding="utf-8") as f:
            content = f.read()

        # æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
        new_section = f"\n\n### è‡ªå‹•ç™ºè¦‹ãƒ‘ã‚¿ãƒ¼ãƒ³ ({pattern['pattern_id']})\n"
        new_section += f"- **ç™ºè¦‹æ—¥æ™‚**: {pattern['timestamp']}\n"
        new_section += f"- **ãƒ‘ã‚¿ãƒ¼ãƒ³**: {pattern['description']}\n"
        new_section += f"- **ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: {json.dumps(pattern['metrics'], ensure_ascii=False)}\n"

        # é©åˆ‡ãªä½ç½®ã«æŒ¿å…¥ï¼ˆå®Ÿè£…ç°¡ç•¥åŒ–ã®ãŸã‚æœ«å°¾ã«è¿½åŠ ï¼‰
        content += new_section

        with open(strategy_doc, "w", encoding="utf-8") as f:
            f.write(content)

    def _append_to_keyword_bank(self, discovery: Dict[str, Any]):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒ³ã‚¯ã¸ã®è¿½åŠ """

        keyword_bank_file = self.memory_root / "keyword_bank.json"

        if keyword_bank_file.exists():
            with open(keyword_bank_file, "r", encoding="utf-8") as f:
                keyword_bank = json.load(f)
        else:
            keyword_bank = {"keywords": [], "last_updated": None}

        keyword_bank["keywords"].append({
            "keyword": discovery["keyword"],
            "discovered_at": discovery["timestamp"],
            "metrics": {
                "ctr": discovery["ctr"],
                "position": discovery["position"],
                "potential": discovery["potential_traffic"]
            }
        })
        keyword_bank["last_updated"] = datetime.now().isoformat()

        with open(keyword_bank_file, "w", encoding="utf-8") as f:
            json.dump(keyword_bank, f, ensure_ascii=False, indent=2)

    def _update_performance_trends(self, milestone: Dict[str, Any]):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ›´æ–°"""

        trends_file = self.memory_root / "performance_trends.json"

        if trends_file.exists():
            with open(trends_file, "r", encoding="utf-8") as f:
                trends = json.load(f)
        else:
            trends = {"metrics": {}, "last_updated": None}

        metric = milestone["metric_name"]
        if metric not in trends["metrics"]:
            trends["metrics"][metric] = []

        trends["metrics"][metric].append({
            "timestamp": milestone["timestamp"],
            "value": milestone["value"],
            "change": milestone["change_percentage"]
        })
        trends["last_updated"] = datetime.now().isoformat()

        with open(trends_file, "w", encoding="utf-8") as f:
            json.dump(trends, f, ensure_ascii=False, indent=2)

    def recall_relevant_memories(self, context: str) -> List[Dict[str, Any]]:
        """é–¢é€£ã™ã‚‹è¨˜æ†¶ã®æƒ³èµ·"""

        relevant_memories = []

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦é–¢é€£è¨˜æ†¶ã‚’æ¤œç´¢
        for category, items in self.memory_bank["categories"].items():
            for item in items:
                # ç°¡æ˜“çš„ãªé–¢é€£æ€§åˆ¤å®šï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šé«˜åº¦ãªå®Ÿè£…ãŒå¿…è¦ï¼‰
                if context.lower() in str(item).lower():
                    relevant_memories.append({
                        "category": category,
                        "memory": item
                    })

        print(f"[æˆ¦ç•¥è¨˜æ†¶] ğŸ” é–¢é€£è¨˜æ†¶ {len(relevant_memories)}ä»¶ã‚’æƒ³èµ·")
        return relevant_memories

    def save_memory_bank(self):
        """ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã®ä¿å­˜"""

        self.memory_bank["total_memories"] = sum(
            len(items) for items in self.memory_bank["categories"].values()
        )
        self.memory_bank["last_updated"] = datetime.now().isoformat()

        bank_file = self.memory_root / "memory_bank.json"
        with open(bank_file, "w", encoding="utf-8") as f:
            json.dump(self.memory_bank, f, ensure_ascii=False, indent=2)

        print(f"[æˆ¦ç•¥è¨˜æ†¶] ğŸ’¾ ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ä¿å­˜: {self.memory_bank['total_memories']}ä»¶")

    def get_memory_stats(self) -> Dict[str, Any]:
        """è¨˜æ†¶çµ±è¨ˆã®å–å¾—"""

        stats = {
            "total_memories": self.memory_bank["total_memories"],
            "by_category": {
                category: len(items)
                for category, items in self.memory_bank["categories"].items()
            },
            "last_updated": self.memory_bank["last_updated"],
            "storage_used": sum(
                os.path.getsize(f) for f in self.memory_root.rglob("*.json")
            ) / 1024  # KB
        }

        return stats


class MemoryIntegration:
    """ä»–ã‚·ã‚¹ãƒ†ãƒ ã¨ã®è¨˜æ†¶çµ±åˆ"""

    def __init__(self):
        self.memory = StrategicMemory()
        print(f"[è¨˜æ†¶çµ±åˆ] è‡ªå¾‹è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå®Œäº†")

    def on_seo_analysis_complete(self, analysis_data: Dict[str, Any]):
        """SEOåˆ†æå®Œäº†æ™‚ã®è‡ªå‹•è¨˜éŒ²"""

        # é«˜CTRã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•ä¿å­˜
        if "top_keywords" in analysis_data:
            for keyword in analysis_data["top_keywords"]:
                if keyword.get("ctr", 0) > 0.2:  # CTR 20%ä»¥ä¸Š
                    self.memory.auto_save_insight(
                        "keyword_discovery",
                        keyword,
                        "SEOåˆ†æã§é«˜CTRã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç™ºè¦‹"
                    )

        # æ”¹å–„æ©Ÿä¼šã‚’è‡ªå‹•ä¿å­˜
        if "opportunities" in analysis_data:
            for opportunity in analysis_data["opportunities"]:
                self.memory.auto_save_insight(
                    "success_pattern",
                    {
                        "type": "seo_opportunity",
                        "description": opportunity.get("description", ""),
                        "metrics": {
                            "potential_traffic": opportunity.get("potential_clicks", 0)
                        }
                    },
                    "SEOæ”¹å–„æ©Ÿä¼šç™ºè¦‹"
                )

    def on_article_published(self, article_data: Dict[str, Any]):
        """è¨˜äº‹å…¬é–‹æ™‚ã®è‡ªå‹•è¨˜éŒ²"""

        self.memory.auto_save_insight(
            "performance_milestone",
            {
                "metric": "articles_published",
                "value": 1,
                "article_title": article_data.get("title", ""),
                "expected_mau_impact": article_data.get("expected_mau_impact", 0)
            },
            "æ–°è¦è¨˜äº‹å…¬é–‹"
        )

    def on_mau_update(self, new_mau: int, previous_mau: int):
        """MAUæ›´æ–°æ™‚ã®è‡ªå‹•è¨˜éŒ²"""

        change_percentage = ((new_mau - previous_mau) / previous_mau * 100) if previous_mau > 0 else 0

        self.memory.auto_save_insight(
            "performance_milestone",
            {
                "metric": "MAU",
                "value": new_mau,
                "previous_value": previous_mau,
                "change_percentage": change_percentage,
                "target_value": 15000,
                "achievement_rate": (new_mau / 15000) * 100
            },
            "MAUæ›´æ–°"
        )

    def on_strategy_decision(self, decision_data: Dict[str, Any]):
        """æˆ¦ç•¥æ±ºå®šæ™‚ã®è‡ªå‹•è¨˜éŒ²"""

        self.memory.auto_save_insight(
            "strategic_decision",
            decision_data,
            "æˆ¦ç•¥çš„æ„æ€æ±ºå®š"
        )

    def on_error_occurred(self, error_data: Dict[str, Any]):
        """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®è‡ªå‹•å­¦ç¿’"""

        self.memory.auto_save_insight(
            "failure_learning",
            {
                "type": error_data.get("error_type", "unknown"),
                "description": error_data.get("error_message", ""),
                "root_cause": error_data.get("root_cause", "unknown"),
                "lesson": error_data.get("lesson", ""),
                "prevention": error_data.get("prevention", "")
            },
            "ã‚¨ãƒ©ãƒ¼ã‹ã‚‰ã®å­¦ç¿’"
        )


def test_strategic_memory():
    """æˆ¦ç•¥è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""

    print("=" * 60)
    print("æˆ¦ç•¥è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    integration = MemoryIntegration()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è‡ªå‹•è¨˜éŒ²ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ

    # 1. SEOåˆ†æçµæœã®è‡ªå‹•ä¿å­˜
    print("\n[ãƒ†ã‚¹ãƒˆ] SEOåˆ†æçµæœã®è‡ªå‹•è¨˜éŒ²")
    integration.on_seo_analysis_complete({
        "top_keywords": [
            {"keyword": "AIå°å…¥ å¤±æ•—", "ctr": 0.35, "position": 8},
            {"keyword": "ChatGPT æ¯”è¼ƒ", "ctr": 0.28, "position": 12}
        ],
        "opportunities": [
            {"description": "ã‚¿ã‚¤ãƒˆãƒ«æœ€é©åŒ–ã§æµå…¥30%å¢—", "potential_clicks": 150}
        ]
    })

    # 2. MAUæ›´æ–°ã®è‡ªå‹•è¨˜éŒ²
    print("\n[ãƒ†ã‚¹ãƒˆ] MAUæ›´æ–°ã®è‡ªå‹•è¨˜éŒ²")
    integration.on_mau_update(12000, 11000)

    # 3. æˆ¦ç•¥æ±ºå®šã®è‡ªå‹•è¨˜éŒ²
    print("\n[ãƒ†ã‚¹ãƒˆ] æˆ¦ç•¥æ±ºå®šã®è‡ªå‹•è¨˜éŒ²")
    integration.on_strategy_decision({
        "type": "content_strategy",
        "title": "ãƒ­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡è¦–",
        "rationale": "Geminiã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æˆåŠŸã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¨ªå±•é–‹",
        "expected_outcome": {"mau_increase": 4000}
    })

    # çµ±è¨ˆè¡¨ç¤º
    stats = integration.memory.get_memory_stats()
    print(f"\nğŸ“Š è¨˜æ†¶çµ±è¨ˆ:")
    print(f"  ç·è¨˜æ†¶æ•°: {stats['total_memories']}")
    print(f"  ã‚«ãƒ†ã‚´ãƒªåˆ¥: {stats['by_category']}")
    print(f"  ä½¿ç”¨å®¹é‡: {stats['storage_used']:.2f} KB")

    # ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ä¿å­˜
    integration.memory.save_memory_bank()

    print("\nâœ… æˆ¦ç•¥è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸å‹•ä½œ")


if __name__ == "__main__":
    test_strategic_memory()